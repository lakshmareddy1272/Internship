{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3ec282fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selenium Web scraping\n",
    "\n",
    "# Lets now import all the required libraries\n",
    "\n",
    "import selenium                      \n",
    "from selenium import webdriver       # importing webdriver module from selenium to open up automated window\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import time                          # use to stop search engine for few seconds\n",
    "\n",
    "import warnings                      # ignore warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "70d653cc",
   "metadata": {},
   "source": [
    "# Q1: Write a python program to scrape data for “Data Analyst” Job position in “Bangalore” location. You have to scrape the\n",
    "\n",
    "    job-title, \n",
    "    job-location, \n",
    "    company_name, \n",
    "    experience_required. \n",
    "    You have to scrape first 10 jobs data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b3b6f9d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# connect to webdriver by location  (1st option)\n",
    "driver = webdriver.Chrome('C:\\webdriver\\chromedriver.exe')   #chrome page will open\n",
    "time.sleep(1)\n",
    "\n",
    "driver.get('https://www.naukri.com/')     # open naukri.com on automated chrome window\n",
    "\n",
    "driver.maximize_window()   # maximize the screen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "748ab670",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding element for designation search bar\n",
    "\n",
    "search_field_designation = driver.find_element_by_class_name(\"suggestor-input \") # job search bar # don't use same class for other search bar\n",
    "search_field_designation.send_keys('Data Analyst')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a63c1be2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# enter Delhi in location search bar\n",
    "\n",
    "search_field_loc = driver.find_element_by_xpath(\"/html/body/div/div[2]/div[3]/div/div/div[3]/div/div/div/input\") # job search bar\n",
    "search_field_loc.send_keys('Bangalore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f46e5fb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Search Button element and click on that\n",
    "\n",
    "search_button = driver.find_element_by_xpath(\"/html/body/div/div[2]/div[3]/div/div/div[6]\")\n",
    "search_button.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3b8b3644",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create 4 empty lists, scraped data will store in these lists\n",
    "\n",
    "job_title = []\n",
    "job_location = []\n",
    "company_name = []\n",
    "exp_req = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3c6f8448",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Senior Data Analyst',\n",
       " 'Senior Data Analyst',\n",
       " 'Data Analyst- customer facing',\n",
       " 'Sr Data Analyst II',\n",
       " 'Business analyst + data Analysis',\n",
       " 'Consultant - Data Analyst',\n",
       " 'Data Analyst',\n",
       " 'Hiring For Data Analyst with SAP ABAP & BW - C2H Wipro',\n",
       " 'Senior Business Analyst - Data Sciences and Advanced Analytics',\n",
       " 'Business and Data Analyst']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1st extract tags where we have all job titles -- use elements for multiple items\n",
    "title_tags = driver.find_elements_by_xpath(\"//a[@class='title fw500 ellipsis']\") \n",
    "\n",
    "for i in title_tags:\n",
    "    title=i.text\n",
    "    job_title.append(title)\n",
    "job_title[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2148e898",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Gurgaon/Gurugram, Bangalore/Bengaluru',\n",
       " 'Hyderabad/Secunderabad, Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# extract job loc tags and then extract text\n",
    "\n",
    "loc_tags = driver.find_elements_by_xpath(\"//li[@class='fleft grey-text br2 placeHolderLi location']/span[1]\")\n",
    "loc_tags\n",
    "\n",
    "for l in loc_tags:\n",
    "    location = l.text\n",
    "    job_location.append(location)\n",
    "    \n",
    "job_location[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5ff462ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Flipkart',\n",
       " 'Thomson Reuters',\n",
       " 'Synamedia',\n",
       " 'IHS Markit',\n",
       " 'Anlage Infotech (I) Pvt. Ltd.',\n",
       " 'Flipkart',\n",
       " 'VOLVO ASSET FINANCE INDIA PRIVATE LIMITED',\n",
       " 'MILLION MINDS INFOTECH PRIVATE LIMITED',\n",
       " 'Vmware',\n",
       " 'CAREERDOST ENTERPRISE']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# extract company tags and then extract text \n",
    "\n",
    "company_tags = driver.find_elements_by_xpath(\"//a[@class='subTitle ellipsis fleft']\")\n",
    "company_tags\n",
    "\n",
    "# now we will extract text from these tags one by one by looping over these tags\n",
    "\n",
    "for c in company_tags:\n",
    "    cname = c.text\n",
    "    company_name.append(cname)\n",
    "company_name[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9f6ff91b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['3-7 Yrs',\n",
       " '2-4 Yrs',\n",
       " '0-3 Yrs',\n",
       " '3-6 Yrs',\n",
       " '5-10 Yrs',\n",
       " '1-3 Yrs',\n",
       " '2-4 Yrs',\n",
       " '7-10 Yrs',\n",
       " '3-7 Yrs',\n",
       " '0-5 Yrs']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# extract job exp. tags and then extract text\n",
    "\n",
    "exp_tags = driver.find_elements_by_xpath(\"//li[@class='fleft grey-text br2 placeHolderLi experience']/span\")\n",
    "exp_tags\n",
    "\n",
    "for e in exp_tags:\n",
    "    experience = e.text\n",
    "    exp_req.append(experience)\n",
    "exp_req[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0f363055",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20 20 20 20\n"
     ]
    }
   ],
   "source": [
    "print(len(job_title),len(company_name),len(job_location),len(exp_req))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d694768d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>JobTitle</th>\n",
       "      <th>CompanyName</th>\n",
       "      <th>ExperienceRequired</th>\n",
       "      <th>JobLocation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Senior Data Analyst</td>\n",
       "      <td>Flipkart</td>\n",
       "      <td>3-7 Yrs</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Senior Data Analyst</td>\n",
       "      <td>Thomson Reuters</td>\n",
       "      <td>2-4 Yrs</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Analyst- customer facing</td>\n",
       "      <td>Synamedia</td>\n",
       "      <td>0-3 Yrs</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sr Data Analyst II</td>\n",
       "      <td>IHS Markit</td>\n",
       "      <td>3-6 Yrs</td>\n",
       "      <td>Gurgaon/Gurugram, Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Business analyst + data Analysis</td>\n",
       "      <td>Anlage Infotech (I) Pvt. Ltd.</td>\n",
       "      <td>5-10 Yrs</td>\n",
       "      <td>Hyderabad/Secunderabad, Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Consultant - Data Analyst</td>\n",
       "      <td>Flipkart</td>\n",
       "      <td>1-3 Yrs</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>VOLVO ASSET FINANCE INDIA PRIVATE LIMITED</td>\n",
       "      <td>2-4 Yrs</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Hiring For Data Analyst with SAP ABAP &amp; BW - C...</td>\n",
       "      <td>MILLION MINDS INFOTECH PRIVATE LIMITED</td>\n",
       "      <td>7-10 Yrs</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Senior Business Analyst - Data Sciences and Ad...</td>\n",
       "      <td>Vmware</td>\n",
       "      <td>3-7 Yrs</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Business and Data Analyst</td>\n",
       "      <td>CAREERDOST ENTERPRISE</td>\n",
       "      <td>0-5 Yrs</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            JobTitle  \\\n",
       "0                                Senior Data Analyst   \n",
       "1                                Senior Data Analyst   \n",
       "2                      Data Analyst- customer facing   \n",
       "3                                 Sr Data Analyst II   \n",
       "4                   Business analyst + data Analysis   \n",
       "5                          Consultant - Data Analyst   \n",
       "6                                       Data Analyst   \n",
       "7  Hiring For Data Analyst with SAP ABAP & BW - C...   \n",
       "8  Senior Business Analyst - Data Sciences and Ad...   \n",
       "9                          Business and Data Analyst   \n",
       "\n",
       "                                 CompanyName ExperienceRequired  \\\n",
       "0                                   Flipkart            3-7 Yrs   \n",
       "1                            Thomson Reuters            2-4 Yrs   \n",
       "2                                  Synamedia            0-3 Yrs   \n",
       "3                                 IHS Markit            3-6 Yrs   \n",
       "4              Anlage Infotech (I) Pvt. Ltd.           5-10 Yrs   \n",
       "5                                   Flipkart            1-3 Yrs   \n",
       "6  VOLVO ASSET FINANCE INDIA PRIVATE LIMITED            2-4 Yrs   \n",
       "7     MILLION MINDS INFOTECH PRIVATE LIMITED           7-10 Yrs   \n",
       "8                                     Vmware            3-7 Yrs   \n",
       "9                      CAREERDOST ENTERPRISE            0-5 Yrs   \n",
       "\n",
       "                                   JobLocation  \n",
       "0                          Bangalore/Bengaluru  \n",
       "1                          Bangalore/Bengaluru  \n",
       "2                          Bangalore/Bengaluru  \n",
       "3        Gurgaon/Gurugram, Bangalore/Bengaluru  \n",
       "4  Hyderabad/Secunderabad, Bangalore/Bengaluru  \n",
       "5                          Bangalore/Bengaluru  \n",
       "6                          Bangalore/Bengaluru  \n",
       "7                          Bangalore/Bengaluru  \n",
       "8                          Bangalore/Bengaluru  \n",
       "9                          Bangalore/Bengaluru  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job_data = pd.DataFrame({})\n",
    "job_data['JobTitle'] = job_title\n",
    "job_data['CompanyName'] = company_name\n",
    "job_data['ExperienceRequired'] = exp_req\n",
    "job_data['JobLocation'] = job_location\n",
    "\n",
    "job_data[:10]"
   ]
  },
  {
   "cell_type": "raw",
   "id": "a61626b2",
   "metadata": {},
   "source": [
    "# Q2: Write a python program to scrape data for “Data Scientist” Job position in “Bangalore” location.\n",
    "\n",
    "        You have to scrape the \n",
    "            job-title, \n",
    "            job-location, \n",
    "            company_name. \n",
    "        You have to scrape first 10 jobs data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5dfe147b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# connect to webdriver by location  (1st option)\n",
    "driver = webdriver.Chrome('C:\\webdriver\\chromedriver.exe')\n",
    "time.sleep(1)\n",
    "\n",
    "driver.get('https://www.naukri.com/')     # open naukri.com on automated chrome window\n",
    "\n",
    "driver.maximize_window()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "00805f9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding element for job search bar\n",
    "\n",
    "search_field_designation = driver.find_element_by_class_name(\"suggestor-input \") # job search bar # don't use same class for other search bar\n",
    "search_field_designation.send_keys('Data Scientist')\n",
    "\n",
    "# enter Delhi in location search bar\n",
    "\n",
    "search_field_loc = driver.find_element_by_xpath(\"/html/body/div/div[2]/div[3]/div/div/div[3]/div/div/div/input\") # job search bar\n",
    "search_field_loc.send_keys('Delhi')\n",
    "\n",
    "# Search Button element and click on that\n",
    "\n",
    "search_button = driver.find_element_by_xpath(\"/html/body/div/div[2]/div[3]/div/div/div[6]\")\n",
    "search_button.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "81eb2542",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create 3 empty lists, scraped data will store in these lists\n",
    "\n",
    "job_title = []\n",
    "job_location = []\n",
    "company_name = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b8644681",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Data Scientist/ Analyst Specialist',\n",
       " 'Data Scientist',\n",
       " 'Lead Data Scientist',\n",
       " 'Senior Data Scientist',\n",
       " 'Data Scientist Opportunity with PayU - Diversity Hiring',\n",
       " 'Data Scientist',\n",
       " 'Junior Data Scientist',\n",
       " 'Data Scientist',\n",
       " 'Assistant Manager/Manager/Senior Manager - Data Scientist',\n",
       " 'Data Scientist/Data Engineer']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1st extract tags where we have all job titles -- use elements for multiple items\n",
    "\n",
    "title_tags = driver.find_elements_by_xpath(\"//a[@class='title fw500 ellipsis']\") \n",
    "\n",
    "for i in title_tags:\n",
    "    title=i.text\n",
    "    job_title.append(title)\n",
    "job_title[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "18529b6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Noida, New Delhi, Gurgaon/Gurugram, Delhi / NCR, Mumbai (All Areas)',\n",
       " 'Hyderabad/Secunderabad, Bangalore/Bengaluru, Delhi / NCR',\n",
       " 'Bangalore/Bengaluru, Delhi / NCR, Mumbai (All Areas)',\n",
       " 'Gurgaon/Gurugram',\n",
       " 'Gurgaon/Gurugram, Bangalore/Bengaluru, Mumbai (All Areas)',\n",
       " 'Noida, Bangalore/Bengaluru',\n",
       " 'Noida',\n",
       " 'New Delhi',\n",
       " 'Gurgaon/Gurugram, Bangalore/Bengaluru',\n",
       " 'Kochi/Cochin, Hyderabad/Secunderabad, Pune, Ahmedabad, Chennai, Bangalore/Bengaluru, Delhi / NCR, Trivandrum/Thiruvananthapuram, Mumbai (All Areas)']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# extract job loc tags and then extract text\n",
    "\n",
    "loc_tags = driver.find_elements_by_xpath(\"//li[@class='fleft grey-text br2 placeHolderLi location']/span[1]\")\n",
    "\n",
    "for l in loc_tags:\n",
    "    location = l.text\n",
    "    job_location.append(location)\n",
    "    \n",
    "job_location[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5356c580",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['TransOrg Solutions Services (P) Ltd.',\n",
       " 'Genpact',\n",
       " 'TransOrg Solutions Services (P) Ltd.',\n",
       " 'Ocrolus East',\n",
       " 'PayU',\n",
       " 'Ashkom Media India Private Limited',\n",
       " 'EASY DATA ANALYTICS TECHNOLOGY PRIVATE LIMITED',\n",
       " 'Pasona',\n",
       " 'Huquo Consulting Pvt. Ltd',\n",
       " 'UST']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# extract company tags and then extract text \n",
    "\n",
    "company_tags = driver.find_elements_by_xpath(\"//a[@class='subTitle ellipsis fleft']\")\n",
    "\n",
    "# now we will extract text from these tags one by one by looping over these tags\n",
    "\n",
    "for c in company_tags:\n",
    "    cname = c.text\n",
    "    company_name.append(cname)\n",
    "company_name[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8a7ac614",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job_Title</th>\n",
       "      <th>Job_Location</th>\n",
       "      <th>Company_Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Scientist/ Analyst Specialist</td>\n",
       "      <td>Noida, New Delhi, Gurgaon/Gurugram, Delhi / NC...</td>\n",
       "      <td>TransOrg Solutions Services (P) Ltd.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Hyderabad/Secunderabad, Bangalore/Bengaluru, D...</td>\n",
       "      <td>Genpact</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Lead Data Scientist</td>\n",
       "      <td>Bangalore/Bengaluru, Delhi / NCR, Mumbai (All ...</td>\n",
       "      <td>TransOrg Solutions Services (P) Ltd.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td>Gurgaon/Gurugram</td>\n",
       "      <td>Ocrolus East</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Scientist Opportunity with PayU - Diversi...</td>\n",
       "      <td>Gurgaon/Gurugram, Bangalore/Bengaluru, Mumbai ...</td>\n",
       "      <td>PayU</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Noida, Bangalore/Bengaluru</td>\n",
       "      <td>Ashkom Media India Private Limited</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Junior Data Scientist</td>\n",
       "      <td>Noida</td>\n",
       "      <td>EASY DATA ANALYTICS TECHNOLOGY PRIVATE LIMITED</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>New Delhi</td>\n",
       "      <td>Pasona</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Assistant Manager/Manager/Senior Manager - Dat...</td>\n",
       "      <td>Gurgaon/Gurugram, Bangalore/Bengaluru</td>\n",
       "      <td>Huquo Consulting Pvt. Ltd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Data Scientist/Data Engineer</td>\n",
       "      <td>Kochi/Cochin, Hyderabad/Secunderabad, Pune, Ah...</td>\n",
       "      <td>UST</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Job_Title  \\\n",
       "0                 Data Scientist/ Analyst Specialist   \n",
       "1                                     Data Scientist   \n",
       "2                                Lead Data Scientist   \n",
       "3                              Senior Data Scientist   \n",
       "4  Data Scientist Opportunity with PayU - Diversi...   \n",
       "5                                     Data Scientist   \n",
       "6                              Junior Data Scientist   \n",
       "7                                     Data Scientist   \n",
       "8  Assistant Manager/Manager/Senior Manager - Dat...   \n",
       "9                       Data Scientist/Data Engineer   \n",
       "\n",
       "                                        Job_Location  \\\n",
       "0  Noida, New Delhi, Gurgaon/Gurugram, Delhi / NC...   \n",
       "1  Hyderabad/Secunderabad, Bangalore/Bengaluru, D...   \n",
       "2  Bangalore/Bengaluru, Delhi / NCR, Mumbai (All ...   \n",
       "3                                   Gurgaon/Gurugram   \n",
       "4  Gurgaon/Gurugram, Bangalore/Bengaluru, Mumbai ...   \n",
       "5                         Noida, Bangalore/Bengaluru   \n",
       "6                                              Noida   \n",
       "7                                          New Delhi   \n",
       "8              Gurgaon/Gurugram, Bangalore/Bengaluru   \n",
       "9  Kochi/Cochin, Hyderabad/Secunderabad, Pune, Ah...   \n",
       "\n",
       "                                     Company_Name  \n",
       "0            TransOrg Solutions Services (P) Ltd.  \n",
       "1                                         Genpact  \n",
       "2            TransOrg Solutions Services (P) Ltd.  \n",
       "3                                    Ocrolus East  \n",
       "4                                            PayU  \n",
       "5              Ashkom Media India Private Limited  \n",
       "6  EASY DATA ANALYTICS TECHNOLOGY PRIVATE LIMITED  \n",
       "7                                          Pasona  \n",
       "8                       Huquo Consulting Pvt. Ltd  \n",
       "9                                             UST  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_job_data = pd.DataFrame({})\n",
    "ds_job_data['Job_Title'] = job_title\n",
    "ds_job_data['Job_Location'] = job_location\n",
    "ds_job_data['Company_Name'] = company_name\n",
    "\n",
    "ds_job_data[:10]"
   ]
  },
  {
   "cell_type": "raw",
   "id": "a3675f57",
   "metadata": {},
   "source": [
    "# Q3: Scrape data using the filters available on the webpage.\n",
    "\n",
    "    You have to use the location and salary filter.\n",
    "    You have to scrape data for “Data Scientist” designation for first 10 job results.\n",
    "    You have to scrape the \n",
    "        1. job-title, \n",
    "        2. job-location, \n",
    "        3. company name, \n",
    "        4. experience required.\n",
    "    The location filter to be used is “Delhi/NCR”. The salary filter to be used is “3-6” lakhs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f6c15c9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# connect to webdriver by location  (1st option)\n",
    "driver = webdriver.Chrome('C:\\webdriver\\chromedriver.exe')\n",
    "time.sleep(1)\n",
    "\n",
    "driver.get('https://www.naukri.com/')     # open naukri.com on automated chrome window\n",
    "\n",
    "driver.maximize_window()\n",
    "time.sleep(2)\n",
    "\n",
    "# Finding element for job search bar\n",
    "\n",
    "search_field_designation = driver.find_element_by_class_name(\"suggestor-input \") # job search bar # don't use same class for other search bar\n",
    "search_field_designation.send_keys('Data Scientist')\n",
    "\n",
    "# Search Button element and click on that\n",
    "\n",
    "search_button = driver.find_element_by_xpath(\"/html/body/div/div[2]/div[3]/div/div/div[6]\")\n",
    "search_button.click()\n",
    "time.sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9f6bf8da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# location filter and salary filter by checking the respective boxes\n",
    "\n",
    "loc_filter_check = driver.find_element_by_xpath(\"/html/body/div[1]/div[3]/div[2]/section[1]/div[2]/div[4]/div[2]/div[3]/label/p/span[1]\")\n",
    "loc_filter_check.click()\n",
    "time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7ed8981a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sal_filter_check = driver.find_element_by_xpath(\"/html/body/div[1]/div[3]/div[2]/section[1]/div[2]/div[5]/div[2]/div[2]/label/p/span[1]\")\n",
    "sal_filter_check.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5e54de70",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_title = []\n",
    "job_location = []\n",
    "company_name = []\n",
    "exp_req = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "af323797",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Data Scientist',\n",
       " 'Junior Data Scientist',\n",
       " 'Associate Data Scientist',\n",
       " 'Associate Scientist - Data Engineering',\n",
       " 'Data Scientist || Software Company || Immediate Joiners To max 30 Days',\n",
       " 'Data Scientist/ Machine Learning, 2022 Passout Can also apply',\n",
       " 'Hiring For Data Analyst and Data Scientist For Gurgaon Location',\n",
       " 'Data Scientist (freelance)',\n",
       " 'Data Scientists',\n",
       " 'Data Scientist']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "title_tags = driver.find_elements_by_xpath(\"//a[@class='title fw500 ellipsis']\") \n",
    "\n",
    "for i in title_tags:\n",
    "    job_title.append(i.text)\n",
    "job_title[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "aa2bdfa3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Noida, Bangalore/Bengaluru',\n",
       " 'Noida',\n",
       " 'Gurgaon/Gurugram',\n",
       " 'Gurgaon/Gurugram',\n",
       " 'Gurgaon/Gurugram, Bangalore/Bengaluru',\n",
       " 'Hyderabad/Secunderabad, Pune, Chennai, Delhi / NCR, Vadodara, Mumbai (All Areas)',\n",
       " 'Noida, Gurgaon/Gurugram, Delhi / NCR',\n",
       " 'New Delhi, Delhi',\n",
       " 'Gurgaon/Gurugram',\n",
       " 'Gurgaon, Bengaluru']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loc_tags = driver.find_elements_by_xpath(\"//li[@class='fleft grey-text br2 placeHolderLi location']/span[1]\")\n",
    "\n",
    "for l in loc_tags:\n",
    "    job_location.append(l.text)\n",
    "    \n",
    "job_location[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f4609919",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Ashkom Media India Private Limited',\n",
       " 'EASY DATA ANALYTICS TECHNOLOGY PRIVATE LIMITED',\n",
       " 'Optum',\n",
       " 'AXA Technology Services India Pvt. Ltd',\n",
       " 'Skyleaf Consultants',\n",
       " 'Creative Hands HR Consultancy',\n",
       " 'Shadow Placements',\n",
       " '2Coms',\n",
       " 'Nibha Infotech Private Limited',\n",
       " 'BlackBuck']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "company_tags = driver.find_elements_by_xpath(\"//a[@class='subTitle ellipsis fleft']\")\n",
    "\n",
    "# extract text from these tags one by one by looping over these tags\n",
    "\n",
    "for c in company_tags:\n",
    "    company_name.append(c.text)\n",
    "company_name[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "47ff1d82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['3-6 Yrs',\n",
       " '1-2 Yrs',\n",
       " '1-5 Yrs',\n",
       " '2-5 Yrs',\n",
       " '3-8 Yrs',\n",
       " '0-4 Yrs',\n",
       " '3-7 Yrs',\n",
       " '2-7 Yrs',\n",
       " '5-8 Yrs',\n",
       " '3-7 Yrs']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# extract job exp. tags and then extract text\n",
    "\n",
    "exp_tags = driver.find_elements_by_xpath(\"//li[@class='fleft grey-text br2 placeHolderLi experience']/span\")\n",
    "exp_tags\n",
    "\n",
    "for e in exp_tags:\n",
    "    experience = e.text\n",
    "    exp_req.append(experience)\n",
    "exp_req[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "15b0f1ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job_Title</th>\n",
       "      <th>Job_Location</th>\n",
       "      <th>Company_Name</th>\n",
       "      <th>Exp_Req</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Noida, Bangalore/Bengaluru</td>\n",
       "      <td>Ashkom Media India Private Limited</td>\n",
       "      <td>3-6 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Junior Data Scientist</td>\n",
       "      <td>Noida</td>\n",
       "      <td>EASY DATA ANALYTICS TECHNOLOGY PRIVATE LIMITED</td>\n",
       "      <td>1-2 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Associate Data Scientist</td>\n",
       "      <td>Gurgaon/Gurugram</td>\n",
       "      <td>Optum</td>\n",
       "      <td>1-5 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Associate Scientist - Data Engineering</td>\n",
       "      <td>Gurgaon/Gurugram</td>\n",
       "      <td>AXA Technology Services India Pvt. Ltd</td>\n",
       "      <td>2-5 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Scientist || Software Company || Immediat...</td>\n",
       "      <td>Gurgaon/Gurugram, Bangalore/Bengaluru</td>\n",
       "      <td>Skyleaf Consultants</td>\n",
       "      <td>3-8 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Data Scientist/ Machine Learning, 2022 Passout...</td>\n",
       "      <td>Hyderabad/Secunderabad, Pune, Chennai, Delhi /...</td>\n",
       "      <td>Creative Hands HR Consultancy</td>\n",
       "      <td>0-4 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Hiring For Data Analyst and Data Scientist For...</td>\n",
       "      <td>Noida, Gurgaon/Gurugram, Delhi / NCR</td>\n",
       "      <td>Shadow Placements</td>\n",
       "      <td>3-7 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Data Scientist (freelance)</td>\n",
       "      <td>New Delhi, Delhi</td>\n",
       "      <td>2Coms</td>\n",
       "      <td>2-7 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Data Scientists</td>\n",
       "      <td>Gurgaon/Gurugram</td>\n",
       "      <td>Nibha Infotech Private Limited</td>\n",
       "      <td>5-8 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Gurgaon, Bengaluru</td>\n",
       "      <td>BlackBuck</td>\n",
       "      <td>3-7 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>New Delhi</td>\n",
       "      <td>Boston Consulting Group</td>\n",
       "      <td>2-5 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Hiring For Senior Data Scientist-Noida</td>\n",
       "      <td>Noida, Greater Noida, Delhi / NCR</td>\n",
       "      <td>Lumiq.ai</td>\n",
       "      <td>2-6 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td>Delhi</td>\n",
       "      <td>iNICU</td>\n",
       "      <td>1-5 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Lead Data Scientist</td>\n",
       "      <td>Gurgaon/Gurugram</td>\n",
       "      <td>KIA INDIA PRIVATE LIMITED</td>\n",
       "      <td>7-10 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Bharuch, Jaipur, Bhopal, Mumbai, Jhansi, Nagpu...</td>\n",
       "      <td>Country Veggie</td>\n",
       "      <td>1-3 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Opening For Data Scientist</td>\n",
       "      <td>Gurgaon/Gurugram</td>\n",
       "      <td>Care Health Insurance</td>\n",
       "      <td>1-5 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Data and applied Scientist</td>\n",
       "      <td>Noida, Hyderabad/Secunderabad, Bangalore/Benga...</td>\n",
       "      <td>Microsoft</td>\n",
       "      <td>3-7 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Associate Data Scientist</td>\n",
       "      <td>Noida</td>\n",
       "      <td>Right Step Consulting</td>\n",
       "      <td>3-6 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Junior AI Data Scientist</td>\n",
       "      <td>New Delhi</td>\n",
       "      <td>Seven Consultancy (HR Solution)</td>\n",
       "      <td>1-6 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Data scientist- Python</td>\n",
       "      <td>Gurgaon/Gurugram</td>\n",
       "      <td>TeamPlus Staffing Solution Pvt Ltd</td>\n",
       "      <td>3-6 Yrs</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Job_Title  \\\n",
       "0                                      Data Scientist   \n",
       "1                               Junior Data Scientist   \n",
       "2                            Associate Data Scientist   \n",
       "3              Associate Scientist - Data Engineering   \n",
       "4   Data Scientist || Software Company || Immediat...   \n",
       "5   Data Scientist/ Machine Learning, 2022 Passout...   \n",
       "6   Hiring For Data Analyst and Data Scientist For...   \n",
       "7                          Data Scientist (freelance)   \n",
       "8                                     Data Scientists   \n",
       "9                                      Data Scientist   \n",
       "10                                     Data Scientist   \n",
       "11             Hiring For Senior Data Scientist-Noida   \n",
       "12                              Senior Data Scientist   \n",
       "13                                Lead Data Scientist   \n",
       "14                                     Data Scientist   \n",
       "15                         Opening For Data Scientist   \n",
       "16                         Data and applied Scientist   \n",
       "17                           Associate Data Scientist   \n",
       "18                           Junior AI Data Scientist   \n",
       "19                             Data scientist- Python   \n",
       "\n",
       "                                         Job_Location  \\\n",
       "0                          Noida, Bangalore/Bengaluru   \n",
       "1                                               Noida   \n",
       "2                                    Gurgaon/Gurugram   \n",
       "3                                    Gurgaon/Gurugram   \n",
       "4               Gurgaon/Gurugram, Bangalore/Bengaluru   \n",
       "5   Hyderabad/Secunderabad, Pune, Chennai, Delhi /...   \n",
       "6                Noida, Gurgaon/Gurugram, Delhi / NCR   \n",
       "7                                    New Delhi, Delhi   \n",
       "8                                    Gurgaon/Gurugram   \n",
       "9                                  Gurgaon, Bengaluru   \n",
       "10                                          New Delhi   \n",
       "11                  Noida, Greater Noida, Delhi / NCR   \n",
       "12                                              Delhi   \n",
       "13                                   Gurgaon/Gurugram   \n",
       "14  Bharuch, Jaipur, Bhopal, Mumbai, Jhansi, Nagpu...   \n",
       "15                                   Gurgaon/Gurugram   \n",
       "16  Noida, Hyderabad/Secunderabad, Bangalore/Benga...   \n",
       "17                                              Noida   \n",
       "18                                          New Delhi   \n",
       "19                                   Gurgaon/Gurugram   \n",
       "\n",
       "                                      Company_Name   Exp_Req  \n",
       "0               Ashkom Media India Private Limited   3-6 Yrs  \n",
       "1   EASY DATA ANALYTICS TECHNOLOGY PRIVATE LIMITED   1-2 Yrs  \n",
       "2                                            Optum   1-5 Yrs  \n",
       "3           AXA Technology Services India Pvt. Ltd   2-5 Yrs  \n",
       "4                              Skyleaf Consultants   3-8 Yrs  \n",
       "5                    Creative Hands HR Consultancy   0-4 Yrs  \n",
       "6                                Shadow Placements   3-7 Yrs  \n",
       "7                                            2Coms   2-7 Yrs  \n",
       "8                   Nibha Infotech Private Limited   5-8 Yrs  \n",
       "9                                        BlackBuck   3-7 Yrs  \n",
       "10                         Boston Consulting Group   2-5 Yrs  \n",
       "11                                        Lumiq.ai   2-6 Yrs  \n",
       "12                                           iNICU   1-5 Yrs  \n",
       "13                       KIA INDIA PRIVATE LIMITED  7-10 Yrs  \n",
       "14                                  Country Veggie   1-3 Yrs  \n",
       "15                           Care Health Insurance   1-5 Yrs  \n",
       "16                                       Microsoft   3-7 Yrs  \n",
       "17                           Right Step Consulting   3-6 Yrs  \n",
       "18                 Seven Consultancy (HR Solution)   1-6 Yrs  \n",
       "19              TeamPlus Staffing Solution Pvt Ltd   3-6 Yrs  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# DS jobs data Delhi/NCR and 3-6L \n",
    "\n",
    "ds_jobs_data = pd.DataFrame({})\n",
    "ds_jobs_data['Job_Title'] = job_title\n",
    "ds_jobs_data['Job_Location'] = job_location\n",
    "ds_jobs_data['Company_Name'] = company_name\n",
    "ds_jobs_data['Exp_Req'] = exp_req\n",
    "\n",
    "ds_jobs_data"
   ]
  },
  {
   "cell_type": "raw",
   "id": "695cfcd8",
   "metadata": {},
   "source": [
    "# Q4: Scrape data of first 100 sunglasses listings on flipkart.com. You have to scrape four attributes:\n",
    "\n",
    "1. Brand\n",
    "2. Product Description\n",
    "3. Price\n",
    "4. Disc %\n",
    "\n",
    "To scrape the data you have to go through following steps:\n",
    "\n",
    "    Go to Flipkart webpage by url : https://www.flipkart.com/\n",
    "    Enter “sunglasses” in the search field where “search for products, brands andmore” is written and click the search icon\n",
    "    After that you will reach to the page having a lot of sunglasses. From this page you can scrap the required data\n",
    "    After scraping data from the first page, go to the “Next” Button at the bottom of the page , then click on it.\n",
    "    Now scrape data from this page\n",
    "    Repeat this until you get data for 100 sunglasses.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "07842b54",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome('C:\\webdriver\\chromedriver.exe')\n",
    "time.sleep(1)\n",
    "\n",
    "driver.get('https://www.flipkart.com/')\n",
    "driver.maximize_window()\n",
    "\n",
    "xbutton = driver.find_element_by_xpath('/html/body/div[2]/div/div/button').click()\n",
    "time.sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "fa0521f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Searching item\n",
    "search_item=driver.find_element_by_xpath('//input[@class=\"_3704LK\"]')\n",
    "search_item.send_keys('Sunglasses')\n",
    "time.sleep(3)\n",
    "\n",
    "# click on the search button\n",
    "search_button = driver.find_element_by_xpath('//*[@id=\"container\"]/div/div[1]/div[1]/div[2]/div[2]/form/div/button')\n",
    "search_button.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e53ca0eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract brand details\n",
    "\n",
    "glass_brand = driver.find_elements_by_xpath('//div[@class=\"_2WkVRV\"]')\n",
    "brand = []\n",
    "for i in glass_brand:\n",
    "    brand.append(i.text)\n",
    "\n",
    "# extract product description\n",
    "prod_desc = driver.find_elements_by_xpath('//a[@class=\"IRpwTa\"]')\n",
    "description = []\n",
    "for i in prod_desc:\n",
    "    description.append(i.text)\n",
    "    \n",
    "# extract price of the product\n",
    "prod_price = driver.find_elements_by_xpath('//div[@class=\"_30jeq3\"]')\n",
    "price = []\n",
    "for i in prod_price:\n",
    "    price.append(i.text)\n",
    "\n",
    "# extract the discount percentage\n",
    "prod_discount = driver.find_elements_by_xpath('//div[@class=\"_3Ay6Sb\"]//span')\n",
    "discount = []\n",
    "for i in prod_discount:\n",
    "    discount.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9317c64e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# page2\n",
    "\n",
    "next_button = driver.find_element_by_xpath('/html/body/div[1]/div/div[3]/div[1]/div[2]/div[12]/div/div/nav/a[11]/span')\n",
    "next_button.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b6f95ff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract brand details\n",
    "\n",
    "glass_brand = driver.find_elements_by_xpath('//div[@class=\"_2WkVRV\"]')\n",
    "\n",
    "for i in glass_brand:\n",
    "    brand.append(i.text)\n",
    "\n",
    "# extract product description\n",
    "prod_desc = driver.find_elements_by_xpath('//a[@class=\"IRpwTa\"]')\n",
    "\n",
    "for i in prod_desc:\n",
    "    description.append(i.text)\n",
    "    \n",
    "# extract price of the product\n",
    "prod_price = driver.find_elements_by_xpath('//div[@class=\"_30jeq3\"]')\n",
    "\n",
    "for i in prod_price:\n",
    "    price.append(i.text)\n",
    "\n",
    "# extract the discount percentage\n",
    "prod_discount = driver.find_elements_by_xpath('//div[@class=\"_3Ay6Sb\"]//span')\n",
    "\n",
    "for i in prod_discount:\n",
    "    discount.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b2b957d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# page3\n",
    "\n",
    "next_button3 = driver.find_element_by_xpath('/html/body/div[1]/div/div[3]/div[1]/div[2]/div[12]/div/div/nav/a[12]')\n",
    "next_button3.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "bd75b319",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract brand details\n",
    "\n",
    "glass_brand = driver.find_elements_by_xpath('//div[@class=\"_2WkVRV\"]')\n",
    "for i in glass_brand:\n",
    "    brand.append(i.text)\n",
    "\n",
    "# extract product description\n",
    "prod_desc = driver.find_elements_by_xpath('//a[@class=\"IRpwTa\"]')\n",
    "for i in prod_desc:\n",
    "    description.append(i.text)\n",
    "\n",
    "# extract price of the product\n",
    "prod_price = driver.find_elements_by_xpath('//div[@class=\"_30jeq3\"]')\n",
    "for i in prod_price:\n",
    "    price.append(i.text)\n",
    "\n",
    "# extract the discount percentage\n",
    "prod_discount = driver.find_elements_by_xpath('//div[@class=\"_3Ay6Sb\"]//span')\n",
    "for i in prod_discount:\n",
    "    discount.append(i.text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b3cfb1a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120 120 120 120\n"
     ]
    }
   ],
   "source": [
    "print(len(brand), len(description), len(price), len(discount))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2b8dc11c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sunglass_Brand</th>\n",
       "      <th>Sunglass_Description</th>\n",
       "      <th>Sunglass_Price</th>\n",
       "      <th>Sunglass_Discount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>VINCENT CHASE</td>\n",
       "      <td>UV Protection Rectangular Sunglasses (50)</td>\n",
       "      <td>₹649</td>\n",
       "      <td>67% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>VINCENT CHASE</td>\n",
       "      <td>UV Protection Cat-eye Sunglasses (54)</td>\n",
       "      <td>₹649</td>\n",
       "      <td>67% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Fastrack</td>\n",
       "      <td>UV Protection Wayfarer Sunglasses (Free Size)</td>\n",
       "      <td>₹719</td>\n",
       "      <td>20% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SUNBEE</td>\n",
       "      <td>UV Protection, Polarized Wayfarer Sunglasses (...</td>\n",
       "      <td>₹283</td>\n",
       "      <td>78% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Fastrack</td>\n",
       "      <td>UV Protection Rectangular Sunglasses (Free Size)</td>\n",
       "      <td>₹639</td>\n",
       "      <td>20% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>VINCENT CHASE</td>\n",
       "      <td>by Lenskart Polarized, UV Protection Aviator S...</td>\n",
       "      <td>₹1,120</td>\n",
       "      <td>43% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Singco India</td>\n",
       "      <td>Gradient, Toughened Glass Lens, UV Protection ...</td>\n",
       "      <td>₹664</td>\n",
       "      <td>77% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Fastrack</td>\n",
       "      <td>UV Protection Aviator Sunglasses (58)</td>\n",
       "      <td>₹1,039</td>\n",
       "      <td>20% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Fastrack</td>\n",
       "      <td>UV Protection Shield Sunglasses (Free Size)</td>\n",
       "      <td>₹709</td>\n",
       "      <td>21% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>ROZZETTA CRAFT</td>\n",
       "      <td>UV Protection Aviator Sunglasses (62)</td>\n",
       "      <td>₹649</td>\n",
       "      <td>74% off</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Sunglass_Brand                               Sunglass_Description  \\\n",
       "0    VINCENT CHASE          UV Protection Rectangular Sunglasses (50)   \n",
       "1    VINCENT CHASE              UV Protection Cat-eye Sunglasses (54)   \n",
       "2         Fastrack      UV Protection Wayfarer Sunglasses (Free Size)   \n",
       "3           SUNBEE  UV Protection, Polarized Wayfarer Sunglasses (...   \n",
       "4         Fastrack   UV Protection Rectangular Sunglasses (Free Size)   \n",
       "..             ...                                                ...   \n",
       "95   VINCENT CHASE  by Lenskart Polarized, UV Protection Aviator S...   \n",
       "96    Singco India  Gradient, Toughened Glass Lens, UV Protection ...   \n",
       "97        Fastrack              UV Protection Aviator Sunglasses (58)   \n",
       "98        Fastrack        UV Protection Shield Sunglasses (Free Size)   \n",
       "99  ROZZETTA CRAFT              UV Protection Aviator Sunglasses (62)   \n",
       "\n",
       "   Sunglass_Price Sunglass_Discount  \n",
       "0            ₹649           67% off  \n",
       "1            ₹649           67% off  \n",
       "2            ₹719           20% off  \n",
       "3            ₹283           78% off  \n",
       "4            ₹639           20% off  \n",
       "..            ...               ...  \n",
       "95         ₹1,120           43% off  \n",
       "96           ₹664           77% off  \n",
       "97         ₹1,039           20% off  \n",
       "98           ₹709           21% off  \n",
       "99           ₹649           74% off  \n",
       "\n",
       "[100 rows x 4 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Data Frame\n",
    "sunglass_db = pd.DataFrame({})\n",
    "sunglass_db['Sunglass_Brand']=brand\n",
    "sunglass_db['Sunglass_Description']=description\n",
    "sunglass_db['Sunglass_Price']=price\n",
    "sunglass_db['Sunglass_Discount']=discount\n",
    "sunglass_db[:100]"
   ]
  },
  {
   "cell_type": "raw",
   "id": "63603f0a",
   "metadata": {},
   "source": [
    "# Q5: Scrape 100 reviews data from flipkart.com for iphone11 phone. You have to go the link: \n",
    "    https://www.flipkart.com/apple-iphone-11-black-64-gb-includes-%20earpods-poweradapter/p/itm0f37c2240b217?pid=MOBFKCTSVZAXUHGR&lid=LSTMOBFKC%20TSVZAXUHGREPBFGI&marketplace\n",
    "\n",
    "        1. Rating\n",
    "        2. Review summary\n",
    "        3. Full review\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ed138374",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome('C:\\webdriver\\chromedriver.exe')   #chrome page will open\n",
    "time.sleep(1)\n",
    "\n",
    "driver.get('https://www.flipkart.com/apple-iphone-11-black-64-gb-includes-%20earpods-poweradapter/p/itm0f37c2240b217?pid=MOBFKCTSVZAXUHGR&lid=LSTMOBFKC%20TSVZAXUHGREPBFGI&marketplace')\n",
    "driver.maximize_window()\n",
    "#xbutton = driver.find_element_by_xpath('/html/body/div[2]/div/div/button').click() -- to close auto pop up login\n",
    "time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f9b9715f",
   "metadata": {},
   "outputs": [],
   "source": [
    "viewallratings = driver.find_element_by_xpath('//div[@class=\"_3UAT2v _16PBlm\"]/span').click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "38b9cb4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "Urls = []\n",
    "Rating = []\n",
    "Review_summary = []\n",
    "Full_review = []   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d6182cab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://www.flipkart.com/apple-iphone-11-black-64-gb-includes-earpods-power-adapter/product-reviews/itm0f37c2240b217?pid=MOBFKCTSVZAXUHGR&lid=LSTMOBFKCTSVZAXUHGR3IXQLM&marketplace=FLIPKART&page=1',\n",
       " 'https://www.flipkart.com/apple-iphone-11-black-64-gb-includes-earpods-power-adapter/product-reviews/itm0f37c2240b217?pid=MOBFKCTSVZAXUHGR&lid=LSTMOBFKCTSVZAXUHGR3IXQLM&marketplace=FLIPKART&page=2',\n",
       " 'https://www.flipkart.com/apple-iphone-11-black-64-gb-includes-earpods-power-adapter/product-reviews/itm0f37c2240b217?pid=MOBFKCTSVZAXUHGR&lid=LSTMOBFKCTSVZAXUHGR3IXQLM&marketplace=FLIPKART&page=3',\n",
       " 'https://www.flipkart.com/apple-iphone-11-black-64-gb-includes-earpods-power-adapter/product-reviews/itm0f37c2240b217?pid=MOBFKCTSVZAXUHGR&lid=LSTMOBFKCTSVZAXUHGR3IXQLM&marketplace=FLIPKART&page=4',\n",
       " 'https://www.flipkart.com/apple-iphone-11-black-64-gb-includes-earpods-power-adapter/product-reviews/itm0f37c2240b217?pid=MOBFKCTSVZAXUHGR&lid=LSTMOBFKCTSVZAXUHGR3IXQLM&marketplace=FLIPKART&page=5',\n",
       " 'https://www.flipkart.com/apple-iphone-11-black-64-gb-includes-earpods-power-adapter/product-reviews/itm0f37c2240b217?pid=MOBFKCTSVZAXUHGR&lid=LSTMOBFKCTSVZAXUHGR3IXQLM&marketplace=FLIPKART&page=6',\n",
       " 'https://www.flipkart.com/apple-iphone-11-black-64-gb-includes-earpods-power-adapter/product-reviews/itm0f37c2240b217?pid=MOBFKCTSVZAXUHGR&lid=LSTMOBFKCTSVZAXUHGR3IXQLM&marketplace=FLIPKART&page=7',\n",
       " 'https://www.flipkart.com/apple-iphone-11-black-64-gb-includes-earpods-power-adapter/product-reviews/itm0f37c2240b217?pid=MOBFKCTSVZAXUHGR&lid=LSTMOBFKCTSVZAXUHGR3IXQLM&marketplace=FLIPKART&page=8',\n",
       " 'https://www.flipkart.com/apple-iphone-11-black-64-gb-includes-earpods-power-adapter/product-reviews/itm0f37c2240b217?pid=MOBFKCTSVZAXUHGR&lid=LSTMOBFKCTSVZAXUHGR3IXQLM&marketplace=FLIPKART&page=9',\n",
       " 'https://www.flipkart.com/apple-iphone-11-black-64-gb-includes-earpods-power-adapter/product-reviews/itm0f37c2240b217?pid=MOBFKCTSVZAXUHGR&lid=LSTMOBFKCTSVZAXUHGR3IXQLM&marketplace=FLIPKART&page=10',\n",
       " 'https://www.flipkart.com/apple-iphone-11-black-64-gb-includes-earpods-power-adapter/product-reviews/itm0f37c2240b217?pid=MOBFKCTSVZAXUHGR&lid=LSTMOBFKCTSVZAXUHGR3IXQLM&marketplace=FLIPKART&page=2']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = driver.find_elements_by_xpath('//nav[@class=\"yFHi8N\"]//a')\n",
    "for i in url:\n",
    "    Urls.append(i.get_attribute('href'))\n",
    "Urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1aa8fdac",
   "metadata": {},
   "outputs": [],
   "source": [
    "for j in Urls:\n",
    "    driver.get(j)\n",
    "    rating = driver.find_elements_by_xpath('//div[@class=\"_3LWZlK _1BLPMq\"]')\n",
    "    for j in rating:\n",
    "        Rating.append(j.text)\n",
    "#Rating[:100]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fc76932d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for j in Urls:\n",
    "    driver.get(j)\n",
    "    rev = driver.find_elements_by_xpath('//p[@class=\"_2-N8zT\"]')\n",
    "    for j in rev:\n",
    "        Review_summary.append(j.text)\n",
    "#Review_summary[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bd63076c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for j in Urls:\n",
    "    driver.get(j)\n",
    "    fr = driver.find_elements_by_xpath('//div[@class=\"t-ZTKy\"]')\n",
    "    for j in fr:\n",
    "        Full_review.append(j.text)\n",
    "#Full_review[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "37dec6b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "107 220 110\n"
     ]
    }
   ],
   "source": [
    "print(len(Rating), len(Review_summary), len(Full_review))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2f33705a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rating</th>\n",
       "      <th>Review_Summary</th>\n",
       "      <th>Full_Review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>Brilliant</td>\n",
       "      <td>The Best Phone for the Money\\n\\nThe iPhone 11 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>Simply awesome</td>\n",
       "      <td>Really satisfied with the Product I received.....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>Best in the market!</td>\n",
       "      <td>Great iPhone very snappy experience as apple k...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>Perfect product!</td>\n",
       "      <td>Amazing phone with great cameras and better ba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Fabulous!</td>\n",
       "      <td>This is my first iOS phone. I am very happy wi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>5</td>\n",
       "      <td>Excellent</td>\n",
       "      <td>A perfect phone and a good battery super camer...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>5</td>\n",
       "      <td>Super!</td>\n",
       "      <td>This is my first ever iPhone.\\nAnd I truly don...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>5</td>\n",
       "      <td>Worth every penny</td>\n",
       "      <td>Undoubtedly Iphone 11 is the most successful m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>5</td>\n",
       "      <td>Fabulous!</td>\n",
       "      <td>I purchased the iPhone 11 a month back. I must...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>5</td>\n",
       "      <td>Wonderful</td>\n",
       "      <td>Nice value for money good and best price I pho...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rating       Review_Summary  \\\n",
       "0       5            Brilliant   \n",
       "1       5       Simply awesome   \n",
       "2       5  Best in the market!   \n",
       "3       5     Perfect product!   \n",
       "4       5            Fabulous!   \n",
       "..    ...                  ...   \n",
       "95      5            Excellent   \n",
       "96      5               Super!   \n",
       "97      5    Worth every penny   \n",
       "98      5            Fabulous!   \n",
       "99      5            Wonderful   \n",
       "\n",
       "                                          Full_Review  \n",
       "0   The Best Phone for the Money\\n\\nThe iPhone 11 ...  \n",
       "1   Really satisfied with the Product I received.....  \n",
       "2   Great iPhone very snappy experience as apple k...  \n",
       "3   Amazing phone with great cameras and better ba...  \n",
       "4   This is my first iOS phone. I am very happy wi...  \n",
       "..                                                ...  \n",
       "95  A perfect phone and a good battery super camer...  \n",
       "96  This is my first ever iPhone.\\nAnd I truly don...  \n",
       "97  Undoubtedly Iphone 11 is the most successful m...  \n",
       "98  I purchased the iPhone 11 a month back. I must...  \n",
       "99  Nice value for money good and best price I pho...  \n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iphone_review_df=pd.DataFrame({'Rating': Rating[:100],\n",
    "                               'Review_Summary': Review_summary[:100],\n",
    "                               'Full_Review': Full_review[:100]})\n",
    "iphone_review_df[:100]"
   ]
  },
  {
   "cell_type": "raw",
   "id": "7249fca5",
   "metadata": {},
   "source": [
    "# Q6: Scrape data for first 100 sneakers you find when you visit flipkart.com and search for “sneakers” in the search field.\n",
    "\n",
    "    You have to scrape 4 attributes of each sneaker:\n",
    "        1. Brand\n",
    "        2. Product Description\n",
    "        3. Price\n",
    "        4. disc %"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "11720bab",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome('C:\\webdriver\\chromedriver.exe')\n",
    "time.sleep(1)\n",
    "\n",
    "driver.get('https://www.flipkart.com/')\n",
    "driver.maximize_window()\n",
    "time.sleep(2)\n",
    "\n",
    "xbutton = driver.find_element_by_xpath('/html/body/div[2]/div/div/button').click()\n",
    "time.sleep(2)\n",
    "\n",
    "#Searching item\n",
    "search_item=driver.find_element_by_xpath('//input[@class=\"_3704LK\"]')\n",
    "search_item.send_keys('Sneakers')\n",
    "time.sleep(3)\n",
    "\n",
    "# click on the search button\n",
    "search_button = driver.find_element_by_xpath('//*[@id=\"container\"]/div/div[1]/div[1]/div[2]/div[2]/form/div/button')\n",
    "search_button.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "1ea8b9f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract brand details\n",
    "\n",
    "sneakers_brand = driver.find_elements_by_xpath('//div[@class=\"_2WkVRV\"]')\n",
    "brand = []\n",
    "for i in sneakers_brand:\n",
    "    brand.append(i.text)\n",
    "\n",
    "# extract product description\n",
    "prod_desc = driver.find_elements_by_xpath('//a[@class=\"IRpwTa\"]')\n",
    "description = []\n",
    "for i in prod_desc:\n",
    "    try:\n",
    "        description.append(i.text)\n",
    "    except:\n",
    "        description.appendend('Desc.. Not available')\n",
    "    \n",
    "# extract price of the product\n",
    "prod_price = driver.find_elements_by_xpath('//div[@class=\"_30jeq3\"]')\n",
    "price = []\n",
    "for i in prod_price:\n",
    "    price.append(i.text)\n",
    "\n",
    "# extract the discount percentage\n",
    "prod_discount = driver.find_elements_by_xpath('//div[@class=\"_3Ay6Sb\"]//span')\n",
    "discount = []\n",
    "for i in prod_discount:\n",
    "    discount.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "84e42e46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# page2\n",
    "\n",
    "next_button = driver.find_element_by_xpath('/html/body/div[1]/div/div[3]/div[1]/div[2]/div[12]/div/div/nav/a[11]/span')\n",
    "next_button.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "3e0c2672",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract brand details\n",
    "\n",
    "sneakers_brand = driver.find_elements_by_xpath('//div[@class=\"_2WkVRV\"]')\n",
    "\n",
    "for i in sneakers_brand:\n",
    "    brand.append(i.text)\n",
    "\n",
    "# extract product description\n",
    "prod_desc = driver.find_elements_by_xpath('//a[@class=\"IRpwTa\"]')\n",
    "\n",
    "for i in prod_desc:\n",
    "    try:\n",
    "        description.append(i.text)\n",
    "    except:\n",
    "        description.appendend('Desc.. Not available')\n",
    "    \n",
    "# extract price of the product\n",
    "prod_price = driver.find_elements_by_xpath('//div[@class=\"_30jeq3\"]')\n",
    "\n",
    "for i in prod_price:\n",
    "    price.append(i.text)\n",
    "    \n",
    "# extract the discount percentage\n",
    "prod_discount = driver.find_elements_by_xpath('//div[@class=\"_3Ay6Sb\"]//span')\n",
    "\n",
    "for i in prod_discount:\n",
    "    discount.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "56d3bd0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# page3\n",
    "\n",
    "next_button3 = driver.find_element_by_xpath('/html/body/div[1]/div/div[3]/div[1]/div[2]/div[12]/div/div/nav/a[12]')\n",
    "next_button3.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "051d2be0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract brand details\n",
    "\n",
    "sneakers_brand = driver.find_elements_by_xpath('//div[@class=\"_2WkVRV\"]')\n",
    "for i in sneakers_brand:\n",
    "    brand.append(i.text)\n",
    "\n",
    "# extract product description\n",
    "prod_desc = driver.find_elements_by_xpath('//a[@class=\"IRpwTa\"]')\n",
    "for i in prod_desc:\n",
    "    try:\n",
    "        description.append(i.text)\n",
    "    except:\n",
    "        description.appendend('Desc.. Not available')\n",
    "\n",
    "# extract price of the product\n",
    "prod_price = driver.find_elements_by_xpath('//div[@class=\"_30jeq3\"]')\n",
    "for i in prod_price:\n",
    "    price.append(i.text)\n",
    "\n",
    "# extract the discount percentage\n",
    "prod_discount = driver.find_elements_by_xpath('//div[@class=\"_3Ay6Sb\"]//span')\n",
    "for i in prod_discount:\n",
    "    discount.append(i.text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "4282b7f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120 105 120 118\n"
     ]
    }
   ],
   "source": [
    "print(len(brand), len(description), len(price), len(discount))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "c76d6da1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sunglass_Brand</th>\n",
       "      <th>Sunglass_Description</th>\n",
       "      <th>Sunglass_Price</th>\n",
       "      <th>Sunglass_Discount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BRUTON</td>\n",
       "      <td>Modern Trendy Sneakers Shoes Sneakers For Men</td>\n",
       "      <td>₹488</td>\n",
       "      <td>62% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HOC</td>\n",
       "      <td>Luxury Fashionable Breathable Casual Sneakers ...</td>\n",
       "      <td>₹449</td>\n",
       "      <td>77% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>URBANBOX</td>\n",
       "      <td>Modern Trendy Sneakers Shoes Sneakers For Men</td>\n",
       "      <td>₹198</td>\n",
       "      <td>80% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BRUTON</td>\n",
       "      <td>STYLISH MENS BLACK SNEAKER Sneakers For Men</td>\n",
       "      <td>₹295</td>\n",
       "      <td>77% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>corsac</td>\n",
       "      <td>Stylish Comfortable Lightweight, Breathable Wa...</td>\n",
       "      <td>₹499</td>\n",
       "      <td>66% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>BRUTON</td>\n",
       "      <td>Casual , Partywear Sneakers Shoes For Men's An...</td>\n",
       "      <td>₹552</td>\n",
       "      <td>78% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Noztile</td>\n",
       "      <td>Sneakers For Men</td>\n",
       "      <td>₹428</td>\n",
       "      <td>50% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>bluemaker</td>\n",
       "      <td>STR2 Sneakers For Men</td>\n",
       "      <td>₹499</td>\n",
       "      <td>37% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Roadster</td>\n",
       "      <td>Sneakers For Men</td>\n",
       "      <td>₹1,799</td>\n",
       "      <td>75% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>India hub</td>\n",
       "      <td>Sneakers For Men</td>\n",
       "      <td>₹499</td>\n",
       "      <td>70% off</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Sunglass_Brand                               Sunglass_Description  \\\n",
       "0          BRUTON      Modern Trendy Sneakers Shoes Sneakers For Men   \n",
       "1             HOC  Luxury Fashionable Breathable Casual Sneakers ...   \n",
       "2        URBANBOX      Modern Trendy Sneakers Shoes Sneakers For Men   \n",
       "3          BRUTON        STYLISH MENS BLACK SNEAKER Sneakers For Men   \n",
       "4          corsac  Stylish Comfortable Lightweight, Breathable Wa...   \n",
       "..            ...                                                ...   \n",
       "95         BRUTON  Casual , Partywear Sneakers Shoes For Men's An...   \n",
       "96        Noztile                                   Sneakers For Men   \n",
       "97      bluemaker                              STR2 Sneakers For Men   \n",
       "98       Roadster                                   Sneakers For Men   \n",
       "99      India hub                                   Sneakers For Men   \n",
       "\n",
       "   Sunglass_Price Sunglass_Discount  \n",
       "0            ₹488           62% off  \n",
       "1            ₹449           77% off  \n",
       "2            ₹198           80% off  \n",
       "3            ₹295           77% off  \n",
       "4            ₹499           66% off  \n",
       "..            ...               ...  \n",
       "95           ₹552           78% off  \n",
       "96           ₹428           50% off  \n",
       "97           ₹499           37% off  \n",
       "98         ₹1,799           75% off  \n",
       "99           ₹499           70% off  \n",
       "\n",
       "[100 rows x 4 columns]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Data Frame\n",
    "sunglass_db = pd.DataFrame({})\n",
    "sunglass_db['Sunglass_Brand']=brand[:100]\n",
    "sunglass_db['Sunglass_Description']=description[:100]\n",
    "sunglass_db['Sunglass_Price']=price[:100]\n",
    "sunglass_db['Sunglass_Discount']=discount[:100]\n",
    "sunglass_db[:100]"
   ]
  },
  {
   "cell_type": "raw",
   "id": "521d6d78",
   "metadata": {},
   "source": [
    "# Q7: Go to the link - https://www.myntra.com/shoes\n",
    "\n",
    "    Set Price filter to “Rs. 7149 to Rs. 14099 ” , Color filter to “Black”,\n",
    "And then scrape First 100 shoes data you get. The data should include \n",
    "    Brand of the shoes , \n",
    "    Short Shoe description, \n",
    "    Price of the shoe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "60c9c25d",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome('C:\\webdriver\\chromedriver.exe')\n",
    "time.sleep(1)\n",
    "\n",
    "driver.get('https://www.myntra.com/shoes')\n",
    "driver.maximize_window()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "5a11e79f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#price and color filter\n",
    "time.sleep(3)\n",
    "p_filter = driver.find_element_by_xpath('/html/body/div[2]/div/div[1]/main/div[3]/div[1]/section/div/div[5]/ul/li[2]/label/div')\n",
    "p_filter.click()\n",
    "time.sleep(5)\n",
    "\n",
    "c_filter = driver.find_element_by_xpath('/html/body/div[2]/div/div[1]/main/div[3]/div[1]/section/div/div[6]/ul/li[1]/label/div')\n",
    "c_filter.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "c23b3b09",
   "metadata": {},
   "outputs": [],
   "source": [
    "Brand = []\n",
    "for i in range(0,3):\n",
    "    br = driver.find_elements_by_xpath('//div[@class=\"product-productMetaInfo\"]/h3')\n",
    "    for j in br:\n",
    "        Brand.append(j.text)\n",
    "    next_button = driver.find_element_by_xpath('//li[@class=\"pagination-next\"]/a')\n",
    "    next_button.click()\n",
    "    time.sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "a46b3c1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "Short_Shoe_description = []\n",
    "for i in range(0,3):\n",
    "    ssd = driver.find_elements_by_xpath('//h4[@class=\"product-product\"]')\n",
    "    for j in ssd:\n",
    "        Short_Shoe_description.append(j.text)\n",
    "    next_button = driver.find_element_by_xpath('//li[@class=\"pagination-next\"]/a')\n",
    "    next_button.click()\n",
    "    time.sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "e8fcde2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "Price = []\n",
    "for i in range(0,3):\n",
    "    pr = driver.find_elements_by_xpath('//div[@class=\"product-price\"]/span[1]')\n",
    "    for j in pr:\n",
    "        Price.append(j.text)\n",
    "    next_button = driver.find_element_by_xpath('//li[@class=\"pagination-next\"]/a')\n",
    "    next_button.click()\n",
    "    time.sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "e5776325",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150 150 150\n"
     ]
    }
   ],
   "source": [
    "print(len(Brand), len(Short_Shoe_description), len(Price))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "350e3184",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brand</th>\n",
       "      <th>Short_Shoe_description</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>UNDER ARMOUR</td>\n",
       "      <td>Women Sneakers</td>\n",
       "      <td>Rs. 11599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ALDO</td>\n",
       "      <td>Women Solid Leather Ballerinas</td>\n",
       "      <td>Rs. 7199Rs. 8999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Skechers</td>\n",
       "      <td>Leather Block Heels</td>\n",
       "      <td>Rs. 7999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ALDO</td>\n",
       "      <td>Leather Flatform Sandals</td>\n",
       "      <td>Rs. 7999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Puma</td>\n",
       "      <td>Woven Design Block Heels</td>\n",
       "      <td>Rs. 12749Rs. 16999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Clarks</td>\n",
       "      <td>Women Block Heel Sandal</td>\n",
       "      <td>Rs. 10705Rs. 11895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>ADIDAS</td>\n",
       "      <td>Embellish Mid-Top Heeled Boots</td>\n",
       "      <td>Rs. 7999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>UNDER ARMOUR</td>\n",
       "      <td>High-Top Block Heeled Boots</td>\n",
       "      <td>Rs. 8999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>J.FONTINI</td>\n",
       "      <td>Solid Leather Kitten Mules</td>\n",
       "      <td>Rs. 9345Rs. 10995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>J.FONTINI</td>\n",
       "      <td>Women Woven Design PU Sneakers</td>\n",
       "      <td>Rs. 8499Rs. 9999</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Brand          Short_Shoe_description               Price\n",
       "0   UNDER ARMOUR                  Women Sneakers           Rs. 11599\n",
       "1           ALDO  Women Solid Leather Ballerinas    Rs. 7199Rs. 8999\n",
       "2       Skechers             Leather Block Heels            Rs. 7999\n",
       "3           ALDO        Leather Flatform Sandals            Rs. 7999\n",
       "4           Puma        Woven Design Block Heels  Rs. 12749Rs. 16999\n",
       "..           ...                             ...                 ...\n",
       "95        Clarks         Women Block Heel Sandal  Rs. 10705Rs. 11895\n",
       "96        ADIDAS  Embellish Mid-Top Heeled Boots            Rs. 7999\n",
       "97  UNDER ARMOUR     High-Top Block Heeled Boots            Rs. 8999\n",
       "98     J.FONTINI      Solid Leather Kitten Mules   Rs. 9345Rs. 10995\n",
       "99     J.FONTINI  Women Woven Design PU Sneakers    Rs. 8499Rs. 9999\n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shoe_df = pd.DataFrame({})\n",
    "shoe_df['Brand'] = Brand\n",
    "shoe_df['Short_Shoe_description'] = Short_Shoe_description\n",
    "shoe_df['Price'] = Price\n",
    "\n",
    "shoe_df[:100]"
   ]
  },
  {
   "cell_type": "raw",
   "id": "e9065807",
   "metadata": {},
   "source": [
    "# Q8: Go to webpage https://www.amazon.in/\n",
    "\n",
    "        Enter “Laptop” in the search field and then click the search icon.\n",
    "        Then set CPU Type filter to “Intel Core i7” and “Intel Core i9” \n",
    "        After setting the filters scrape first 10 laptops data. You have to scrape 3 attributesfor each laptop:\n",
    "            1. Title\n",
    "            2. Ratings\n",
    "            3. Price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "4ccdb964",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome('C:\\webdriver\\chromedriver.exe')\n",
    "time.sleep(1)\n",
    "\n",
    "driver.get('https://www.amazon.in/')\n",
    "driver.maximize_window()\n",
    "\n",
    "search_field = driver.find_element_by_id('twotabsearchtextbox')\n",
    "search_field.send_keys('Laptop')\n",
    "time.sleep(2)\n",
    "\n",
    "search_button = driver.find_element_by_xpath('//div[@class=\"nav-search-submit nav-sprite\"]')\n",
    "search_button.click()\n",
    "time.sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "7f450a40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# i7 and i9 filter selection # both selection not working for me\n",
    "# i7 only selected\n",
    "cpu1_filter =  driver.find_element_by_xpath('/html/body/div[1]/div[2]/div[1]/div[2]/div/div[3]/span/div[1]/div/div/div[6]/ul[4]/li[13]/span')\n",
    "cpu1_filter.click()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "60e4a4c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MSI Katana GF66 Gaming, Intel i7-11800H, 15.6\"...</td>\n",
       "      <td>5.0 out of 5 stars</td>\n",
       "      <td>91,499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MSI Modern 14, Intel i7-1195G7, 14\" FHD IPS-Le...</td>\n",
       "      <td>4.0 out of 5 stars</td>\n",
       "      <td>76,490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Mi Notebook Ultra 3.2K Resolution Display Inte...</td>\n",
       "      <td>4.3 out of 5 stars</td>\n",
       "      <td>77,999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ASUS VivoBook 14 (2021), 14-inch (35.56 cms) F...</td>\n",
       "      <td>4.5 out of 5 stars</td>\n",
       "      <td>57,490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Lenovo ThinkBook 15 Intel 11th Gen Core i7 15....</td>\n",
       "      <td>4.4 out of 5 stars</td>\n",
       "      <td>86,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>HP Pavilion 14, 11th Gen Intel Core i7-16GB RA...</td>\n",
       "      <td>4.4 out of 5 stars</td>\n",
       "      <td>86,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ASUS TUF Gaming F15 (2021), 15.6\" (39.62 cms) ...</td>\n",
       "      <td>4.6 out of 5 stars</td>\n",
       "      <td>89,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Samsung Galaxy Book2 Intel 12th Gen core i7 Ev...</td>\n",
       "      <td>3.0 out of 5 stars</td>\n",
       "      <td>79,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>HP Pavilion x360 11th Gen Intel Core i7 14 inc...</td>\n",
       "      <td>4.0 out of 5 stars</td>\n",
       "      <td>85,890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>LG Gram 16 inches Intel Evo 11th Gen Core i7 U...</td>\n",
       "      <td>4.3 out of 5 stars</td>\n",
       "      <td>1,01,112</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Title              Rating  \\\n",
       "0  MSI Katana GF66 Gaming, Intel i7-11800H, 15.6\"...  5.0 out of 5 stars   \n",
       "1  MSI Modern 14, Intel i7-1195G7, 14\" FHD IPS-Le...  4.0 out of 5 stars   \n",
       "2  Mi Notebook Ultra 3.2K Resolution Display Inte...  4.3 out of 5 stars   \n",
       "3  ASUS VivoBook 14 (2021), 14-inch (35.56 cms) F...  4.5 out of 5 stars   \n",
       "4  Lenovo ThinkBook 15 Intel 11th Gen Core i7 15....  4.4 out of 5 stars   \n",
       "5  HP Pavilion 14, 11th Gen Intel Core i7-16GB RA...  4.4 out of 5 stars   \n",
       "6  ASUS TUF Gaming F15 (2021), 15.6\" (39.62 cms) ...  4.6 out of 5 stars   \n",
       "7  Samsung Galaxy Book2 Intel 12th Gen core i7 Ev...  3.0 out of 5 stars   \n",
       "8  HP Pavilion x360 11th Gen Intel Core i7 14 inc...  4.0 out of 5 stars   \n",
       "9  LG Gram 16 inches Intel Evo 11th Gen Core i7 U...  4.3 out of 5 stars   \n",
       "\n",
       "      Price  \n",
       "0    91,499  \n",
       "1    76,490  \n",
       "2    77,999  \n",
       "3    57,490  \n",
       "4    86,990  \n",
       "5    86,990  \n",
       "6    89,990  \n",
       "7    79,990  \n",
       "8    85,890  \n",
       "9  1,01,112  "
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "title = []\n",
    "tit = driver.find_elements_by_xpath('//h2[@class=\"a-size-mini a-spacing-none a-color-base s-line-clamp-2\"]')\n",
    "for i in tit:\n",
    "    title.append(i.text)\n",
    "#title\n",
    "\n",
    "Ratings = []\n",
    "rat = driver.find_elements_by_xpath('//span[@class=\"a-icon-alt\"]')\n",
    "for i in rat:\n",
    "    Ratings.append(i.get_attribute('textContent'))\n",
    "#Ratings\n",
    "\n",
    "Price = []\n",
    "pr = driver.find_elements_by_xpath('//span[@class=\"a-price-whole\"]')\n",
    "for i in pr:\n",
    "    Price.append(i.text)\n",
    "Price\n",
    "\n",
    "# i9_df\n",
    "i9_df = pd.DataFrame({})\n",
    "i9_df['Title']=title[:10]\n",
    "i9_df['Rating']=Ratings[:10]\n",
    "i9_df['Price']=Price[:10]\n",
    "i9_df[:10]\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "a6b1d16d",
   "metadata": {},
   "source": [
    "# Q9: Write a python program to scrape data for first 10 job results for Data Scientist Designation in Noida location. \n",
    "\n",
    "    You have to scrape \n",
    "        company name, \n",
    "        No. of days ago when job was posted, \n",
    "        Rating of the company.\n",
    "    This task will be done in following steps:\n",
    "    1. First get the webpage https://www.ambitionbox.com/\n",
    "    2. Click on the Jobs option\n",
    "    3. After reaching to the next webpage, In place of “Search by Designations, Companies, Skills” enter \n",
    "        “Data Scientist” and click on search button.\n",
    "    4. You will reach to the following web page click on location and in place of “Search location” enter “Noida” \n",
    "        and select location “Noida”.\n",
    "    5. Then scrape the data for the first 10 jobs results you get on the above shown page.\n",
    "    6. Finally create a dataframe of the scraped data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "de09c657",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome('C:\\webdriver\\chromedriver.exe')\n",
    "time.sleep(1)\n",
    "\n",
    "driver.get('https://www.ambitionbox.com/')\n",
    "driver.maximize_window()\n",
    "time.sleep(2)\n",
    "\n",
    "field_button = driver.find_element_by_xpath(\"//a[@class='link jobs']\")\n",
    "field_button.click()\n",
    "time.sleep(2)\n",
    "\n",
    "search_design = driver.find_element_by_xpath('//input[@title=\"Enter Designation, Company or a Skill\"]')\n",
    "search_design.send_keys('Data Scientist')\n",
    "time.sleep(2)\n",
    "\n",
    "search_button = driver.find_element_by_xpath('//button[@class=\"ab_btn search-btn round\"]')\n",
    "search_button.click()\n",
    "time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "fb736504",
   "metadata": {},
   "outputs": [],
   "source": [
    "loc_click = driver.find_element_by_xpath('/html/body/div/div/div/div[2]/div[1]/div[2]/div[1]/div/div/div/div[2]/div[1]')\n",
    "loc_click.click()\n",
    "time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "51a2aeb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "loc_enter = driver.find_element_by_xpath('/html/body/div/div/div/div[2]/div[1]/div[2]/div[1]/div/div/div/div[2]/div[2]/div/div[2]/input')\n",
    "loc_enter.send_keys('Noida')\n",
    "time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "c68fc9ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rb - radio button\n",
    "loc_rb_selection = driver.find_element_by_xpath('/html/body/div/div/div/div[2]/div[1]/div[2]/div[1]/div/div/div/div[2]/div[2]/div/div[3]/div[1]/div[1]/div/label')\n",
    "loc_rb_selection.click()\n",
    "time.sleep(2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "4475e570",
   "metadata": {},
   "outputs": [],
   "source": [
    "company_name = []\n",
    "job_posted_on = []\n",
    "Rating_company = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "f3137017",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company_Name</th>\n",
       "      <th>Job_Posted_on</th>\n",
       "      <th>Rating_company</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>EXL Services.com ( I ) Pvt. Ltd.</td>\n",
       "      <td>8d ago</td>\n",
       "      <td>3.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GENPACT India Private Limited</td>\n",
       "      <td>20d ago</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TECHNIP GLOBAL BUSINESS SERVICES PRIVATE LIMITED</td>\n",
       "      <td>6d ago</td>\n",
       "      <td>3.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GENPACT India Private Limited</td>\n",
       "      <td>1mon ago</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Bristlecone India Limited</td>\n",
       "      <td>15d ago</td>\n",
       "      <td>3.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Zyoin</td>\n",
       "      <td>19d ago</td>\n",
       "      <td>4.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Ashkom Media India Private Limited</td>\n",
       "      <td>6d ago</td>\n",
       "      <td>3.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Newgen Software Technologies Ltd.</td>\n",
       "      <td>21d ago</td>\n",
       "      <td>3.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>JK Technosoft Ltd</td>\n",
       "      <td>1mon ago</td>\n",
       "      <td>3.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Pitney Bowes India Pvt Ltd</td>\n",
       "      <td>1mon ago</td>\n",
       "      <td>4.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       Company_Name Job_Posted_on  \\\n",
       "0                  EXL Services.com ( I ) Pvt. Ltd.        8d ago   \n",
       "1                     GENPACT India Private Limited       20d ago   \n",
       "2  TECHNIP GLOBAL BUSINESS SERVICES PRIVATE LIMITED        6d ago   \n",
       "3                     GENPACT India Private Limited      1mon ago   \n",
       "4                         Bristlecone India Limited       15d ago   \n",
       "5                                             Zyoin       19d ago   \n",
       "6                Ashkom Media India Private Limited        6d ago   \n",
       "7                 Newgen Software Technologies Ltd.       21d ago   \n",
       "8                                 JK Technosoft Ltd      1mon ago   \n",
       "9                        Pitney Bowes India Pvt Ltd      1mon ago   \n",
       "\n",
       "  Rating_company  \n",
       "0            3.9  \n",
       "1            4.0  \n",
       "2            3.9  \n",
       "3            4.0  \n",
       "4            3.8  \n",
       "5            4.1  \n",
       "6            3.7  \n",
       "7            3.5  \n",
       "8            3.7  \n",
       "9            4.2  "
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c_name = driver.find_elements_by_xpath('//p[@class=\"company body-medium\"]')\n",
    "for i in c_name:\n",
    "    company_name.append(i.text)\n",
    "    \n",
    "job_posted = driver.find_elements_by_xpath('//div[@class=\"other-info\"]/span[1]')\n",
    "for i in job_posted:\n",
    "    job_posted_on.append(i.text)\n",
    "    \n",
    "rat_comp = driver.find_elements_by_xpath('//span[@class=\"body-small\"]')\n",
    "for i in rat_comp:\n",
    "    Rating_company.append(i.text)\n",
    "\n",
    "#df\n",
    "    \n",
    "noida_df = pd.DataFrame({})\n",
    "noida_df['Company_Name'] = company_name\n",
    "noida_df['Job_Posted_on'] = job_posted_on\n",
    "noida_df['Rating_company'] = Rating_company\n",
    "\n",
    "noida_df"
   ]
  },
  {
   "cell_type": "raw",
   "id": "63b16002",
   "metadata": {},
   "source": [
    "# Q10: Write a python program to scrape the salary data for Data Scientist designation.\n",
    "\n",
    "    You have to scrape Company name, Number of salaries, Average salary, Min salary, Max salary\n",
    "    The above task will be, done as shown in the below steps:\n",
    "        1. First get the webpage https://www.ambitionbox.com/\n",
    "        2. Click on the salaries option as shown in the image.\n",
    "        3. After reaching to the following webpage, In place of “Search Job Profile” enters “Data Scientist” and\n",
    "           then click on “Data Scientist”.\n",
    "        4. Scrape the data for the first 10 companies. Scrape the \n",
    "            company name, \n",
    "            total salary record, \n",
    "            average salary, \n",
    "            minimum salary, \n",
    "            maximum salary, \n",
    "            experience required.\n",
    "        5. Store the data in a dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "4b840f11",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome('C:\\webdriver\\chromedriver.exe')\n",
    "time.sleep(1)\n",
    "\n",
    "driver.get('https://www.ambitionbox.com/')\n",
    "driver.maximize_window()\n",
    "time.sleep(2)\n",
    "\n",
    "sal_button = driver.find_element_by_xpath('//a[@class=\"link salaries\"]')\n",
    "sal_button.click()\n",
    "time.sleep(2)\n",
    "\n",
    "search_job_profile = driver.find_element_by_xpath('//input[@type=\"searchbox\"]')\n",
    "search_job_profile.send_keys('Data Scientist')\n",
    "time.sleep(2)\n",
    "\n",
    "# suggestion selection\n",
    "sugg_select = driver.find_element_by_xpath('/html/body/div/div/div/main/section[1]/div[2]/div[1]/span/div/div/div[1]')\n",
    "sugg_select.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "15d22deb",
   "metadata": {},
   "outputs": [],
   "source": [
    "company_name = []\n",
    "total_sal_record = []\n",
    "average_sal = []\n",
    "minimum_sal = []\n",
    "maximum_sal = []\n",
    "exp_req = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "3c8138a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company_Name</th>\n",
       "      <th>Total_Sal_Record</th>\n",
       "      <th>Minimum_Salary</th>\n",
       "      <th>Average_Salary</th>\n",
       "      <th>Maximum_Salary</th>\n",
       "      <th>Exp_Req</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Walmart</td>\n",
       "      <td>based on 11 salaries</td>\n",
       "      <td>₹ 25.0L</td>\n",
       "      <td>₹ 29.7L</td>\n",
       "      <td>₹ 35.0L</td>\n",
       "      <td>Data Scientist . 3 yrs exp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ab Inbev</td>\n",
       "      <td>based on 32 salaries</td>\n",
       "      <td>₹ 15.0L</td>\n",
       "      <td>₹ 20.5L</td>\n",
       "      <td>₹ 25.5L</td>\n",
       "      <td>Data Scientist . 3-4 yrs exp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Reliance Jio</td>\n",
       "      <td>based on 10 salaries</td>\n",
       "      <td>₹ 5.6L</td>\n",
       "      <td>₹ 18.9L</td>\n",
       "      <td>₹ 26.2L</td>\n",
       "      <td>Data Scientist . 4 yrs exp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ZS</td>\n",
       "      <td>based on 15 salaries</td>\n",
       "      <td>₹ 9.8L</td>\n",
       "      <td>₹ 15.9L</td>\n",
       "      <td>₹ 20.0L</td>\n",
       "      <td>Data Scientist . 2 yrs exp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Optum</td>\n",
       "      <td>based on 27 salaries</td>\n",
       "      <td>₹ 11.0L</td>\n",
       "      <td>₹ 15.2L</td>\n",
       "      <td>₹ 22.0L</td>\n",
       "      <td>Data Scientist . 3-4 yrs exp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Fractal Analytics</td>\n",
       "      <td>based on 81 salaries</td>\n",
       "      <td>₹ 9.5L</td>\n",
       "      <td>₹ 15.2L</td>\n",
       "      <td>₹ 22.0L</td>\n",
       "      <td>Data Scientist . 2-4 yrs exp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Tiger Analytics</td>\n",
       "      <td>based on 46 salaries</td>\n",
       "      <td>₹ 9.0L</td>\n",
       "      <td>₹ 14.8L</td>\n",
       "      <td>₹ 20.0L</td>\n",
       "      <td>Data Scientist . 2-4 yrs exp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>UnitedHealth</td>\n",
       "      <td>based on 53 salaries</td>\n",
       "      <td>₹ 8.3L</td>\n",
       "      <td>₹ 14.0L</td>\n",
       "      <td>₹ 20.5L</td>\n",
       "      <td>Data Scientist . 2-4 yrs exp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Verizon</td>\n",
       "      <td>based on 14 salaries</td>\n",
       "      <td>₹ 10.0L</td>\n",
       "      <td>₹ 12.7L</td>\n",
       "      <td>₹ 21.0L</td>\n",
       "      <td>Data Scientist . 4 yrs exp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Ganit Business Solutions</td>\n",
       "      <td>based on 13 salaries</td>\n",
       "      <td>₹ 8.5L</td>\n",
       "      <td>₹ 12.4L</td>\n",
       "      <td>₹ 15.0L</td>\n",
       "      <td>Data Scientist . 4 yrs exp</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Company_Name      Total_Sal_Record Minimum_Salary  \\\n",
       "0                   Walmart  based on 11 salaries        ₹ 25.0L   \n",
       "1                  Ab Inbev  based on 32 salaries        ₹ 15.0L   \n",
       "2              Reliance Jio  based on 10 salaries         ₹ 5.6L   \n",
       "3                        ZS  based on 15 salaries         ₹ 9.8L   \n",
       "4                     Optum  based on 27 salaries        ₹ 11.0L   \n",
       "5         Fractal Analytics  based on 81 salaries         ₹ 9.5L   \n",
       "6           Tiger Analytics  based on 46 salaries         ₹ 9.0L   \n",
       "7              UnitedHealth  based on 53 salaries         ₹ 8.3L   \n",
       "8                   Verizon  based on 14 salaries        ₹ 10.0L   \n",
       "9  Ganit Business Solutions  based on 13 salaries         ₹ 8.5L   \n",
       "\n",
       "  Average_Salary Maximum_Salary                       Exp_Req  \n",
       "0        ₹ 29.7L        ₹ 35.0L    Data Scientist . 3 yrs exp  \n",
       "1        ₹ 20.5L        ₹ 25.5L  Data Scientist . 3-4 yrs exp  \n",
       "2        ₹ 18.9L        ₹ 26.2L    Data Scientist . 4 yrs exp  \n",
       "3        ₹ 15.9L        ₹ 20.0L    Data Scientist . 2 yrs exp  \n",
       "4        ₹ 15.2L        ₹ 22.0L  Data Scientist . 3-4 yrs exp  \n",
       "5        ₹ 15.2L        ₹ 22.0L  Data Scientist . 2-4 yrs exp  \n",
       "6        ₹ 14.8L        ₹ 20.0L  Data Scientist . 2-4 yrs exp  \n",
       "7        ₹ 14.0L        ₹ 20.5L  Data Scientist . 2-4 yrs exp  \n",
       "8        ₹ 12.7L        ₹ 21.0L    Data Scientist . 4 yrs exp  \n",
       "9        ₹ 12.4L        ₹ 15.0L    Data Scientist . 4 yrs exp  "
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c_name = driver.find_elements_by_xpath('//div[@class=\"name\"]/a')\n",
    "for cn in c_name:\n",
    "    company_name.append(cn.text)\n",
    "#company_name\n",
    "\n",
    "t_s_r = driver.find_elements_by_xpath('//div[@class=\"name\"]/span')\n",
    "for tsr in t_s_r:\n",
    "    total_sal_record.append(tsr.text)\n",
    "#total_sal_record\n",
    "\n",
    "minsal = driver.find_elements_by_xpath('//div[@class=\"salary-values\"]/div[1]')\n",
    "for ms in minsal:\n",
    "    minimum_sal.append(ms.text)\n",
    "#minimum_sal\n",
    "\n",
    "avgsal = driver.find_elements_by_xpath('//p[@class=\"averageCtc\"]')\n",
    "for avgs in avgsal:\n",
    "    average_sal.append(avgs.text)\n",
    "#average_sal\n",
    "\n",
    "maxsal = driver.find_elements_by_xpath('//div[@class=\"salary-values\"]/div[2]')\n",
    "for ms in maxsal:\n",
    "    maximum_sal.append(ms.text)\n",
    "#maximum_sal\n",
    "\n",
    "exp = driver.find_elements_by_xpath('//div[@class=\"salaries sbold-list-header\"]')\n",
    "for e in exp:\n",
    "    exp_req.append(e.text.replace('\\n', ''))\n",
    "#exp_req -- format change require it is not proper output.\n",
    "\n",
    "DS_Sal_DB = pd.DataFrame({})\n",
    "DS_Sal_DB['Company_Name'] = company_name\n",
    "DS_Sal_DB['Total_Sal_Record'] = total_sal_record\n",
    "DS_Sal_DB['Minimum_Salary']= minimum_sal\n",
    "DS_Sal_DB['Average_Salary'] = average_sal\n",
    "DS_Sal_DB['Maximum_Salary'] = maximum_sal\n",
    "DS_Sal_DB['Exp_Req'] = exp_req\n",
    "\n",
    "DS_Sal_DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1120b01a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
